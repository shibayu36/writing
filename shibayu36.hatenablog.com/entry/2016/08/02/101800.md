---
Title: 今日のElasticsearch学び Vol.1 - Analyzer編
Category:
- tech
- elasticsearch
Date: 2016-08-02T10:18:00+09:00
URL: https://blog.shibayu36.org/entry/2016/08/02/101800
EditURL: https://blog.hatena.ne.jp/shiba_yu36/shibayu36.hatenablog.com/atom/entry/10328749687177128103
---

　Elasticsearchをやっていると日々学びがありすぎる。しかし、それを毎回いい感じにまとめるのは大変すぎるので、とりあえずいろいろ整理がつくまで雑に今日の学びとしてまとめていきたい。

　さて今日はanalyzer周りについて学んだ。

* AnalyzerはTokenizer, TokenFilter, CharFilterから成り立つ
　AnalyzerはTokenizer, TokenFilter, CharFilterから成り立つ。ドキュメントは[https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis.html:title] や https://www.elastic.co/guide/en/elasticsearch/guide/2.x/analysis-intro.html:title あたりが参考になる。

>>
Analyzers are composed of a single Tokenizer and zero or more TokenFilters. The tokenizer may be preceded by one or more CharFilters.
<<

と書いてあるとおり、Tokenizerは1つ、TokenFilterは0以上、CharFiltersも1以上指定することもできる。CharFiltersの記述がわかりにくいけど、つまり0以上指定できるということなのかな？

　この3つがどのように関係しているかは [https://www.elastic.co/guide/en/elasticsearch/guide/2.x/analysis-intro.html:title=こちら] を参照すると載っている。

- 文字列を渡すと、CharFilter -> Tokenizer -> TokenFilterの順で処理される
- CharFilterはまず文書全体を処理する
-- 例: HTML除去など
- Tokenizerは文字列をtermに分割する
- TokenFilterは個々のtermを処理する
-- 例: 助詞の除去など

* ICU Analysis PluginでNFKC正規化ができる
　検索の精度を上げるために、半角全角統一とか、小文字統一とかを行いたい時がある。この場合はICU Analysis Pluginを使うといい。

- https://www.elastic.co/guide/en/elasticsearch/plugins/current/analysis-icu.html:title
- https://medium.com/hello-elasticsearch/elasticsearch-c98fd9ce6a18#.ev04seagu:title

　[https://www.elastic.co/guide/en/elasticsearch/plugins/current/analysis-icu-normalization-charfilter.html:title=ICU Normalization Character Filter] というのを利用すれば、Tokenizeの前に一回NFKC正規化してくれるので、トークナイズの精度も上がる。

　このCharFilterのデフォルトではnfkc_cfという形式での正規化がかけられている。nfkc_cfを使えば、小文字統一とNFKC正規化をかけてくれるみたい(?)だった。NFKC正規化は[http://nomenclator.la.coocan.jp/unicode/normalization.htm:title]とか[http://qiita.com/y-ken/items/d08eb7f66c8fb2fa7d21:title]とかを見てもらえば良さそう。

　以上から、とりあえず日本語検索をするにはICU Normalization Character Filterをかけておけば良いという結論に至った。

* analysisの設定について
雑に学んだことを書いておく。

- [https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-create-index.html:title=create index API]でanalysisの設定も出来る
- Analyzer, Tokenizer, TokenFilter, CharFilter全て自分で名前を付けて定義できる
- analyzerのtype customを利用すれば自分でTokenizer, TokenFilter, CharFilterを組み合わせてAnalyzerを定義できる
- [https://www.elastic.co/guide/en/elasticsearch/plugins/current/analysis-kuromoji-tokenizer.html:title=kuromoji_tokenizer]の、search modeを使えば、いい感じに日本語を検索用にtokenizeしてくれる
- [https://www.elastic.co/guide/en/elasticsearch/plugins/current/analysis-kuromoji-speech.html:title=kuromoji_part_of_speech token filter]を使えば、助詞とかのあまり検索に役立たない品詞を除去してくれる
- [https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-keyword-tokenizer.html:title=Keyword Tokenizer]を使うと、渡したものを特にトークナイズせずにそのまま1つのtermとして出力してくれる

